<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>博弈论 on 嘉树的世界</title><link>https://cwleo.github.io/tags/%E5%8D%9A%E5%BC%88%E8%AE%BA/</link><description>Recent content in 博弈论 on 嘉树的世界</description><generator>Hugo</generator><language>zh</language><copyright>2023–2024 嘉树.</copyright><lastBuildDate>Fri, 21 Jul 2023 15:37:24 +0800</lastBuildDate><atom:link href="https://cwleo.github.io/tags/%E5%8D%9A%E5%BC%88%E8%AE%BA/index.xml" rel="self" type="application/rss+xml"/><item><title>Micro QE 备考练习</title><link>https://cwleo.github.io/posts/micro-qe-preparation/</link><pubDate>Fri, 09 Jun 2023 16:22:12 +0800</pubDate><guid>https://cwleo.github.io/posts/micro-qe-preparation/</guid><description>本来计划做一份所有往年题的答案（已经全部做好了但希望打出一份电子版），但不幸考前🐑了，只完成此三题的誊抄，姑且留个纪念吧。
Problem 1 (stochastic dominance) Consider lotteries $L_1\equiv(p_1\circ x_1,p_2\circ x_2)$ and $L_2\equiv(1\circ \bar{x})$, where $\bar{x} &amp;gt; p_1x_1+p_2x_2$, and $\bar{x}&amp;lt;x_2$. Let $x$ denote the outcome of $L_1$ and $\widetilde{x}$ the outcome of $L_2$. ($L_2$ is a trivial lottery. So $\widetilde{x}$ is a random variable that equals $\bar{x}$ with probability one.) Let $z$ denote the outcome of lottery
$$ L_3 \equiv (q_1\circ z_1, \dots, q_i\circ z_i, \dots, q_n\circ z_n), $$
where $n$ is some finite number greater than 1.</description></item><item><title>Bayesian Persuasion</title><link>https://cwleo.github.io/posts/bayesian-persuasion/</link><pubDate>Wed, 08 Mar 2023 22:25:46 +0800</pubDate><guid>https://cwleo.github.io/posts/bayesian-persuasion/</guid><description>内容提要 本文是基于 Kamenica and Gentzkow (2011) 的学习笔记，仅对微观课上覆盖的内容做了分析，目的只是通过考试，并不是对文章的全面剖析，但由于上课时一头雾水，为了彻底理解均衡的概念，有必要深入学习。以下分为两节，第一节直接介绍模型框架和重要推论，第二节给出解题的一般方法，此方法是几何直观的，依赖于第一节的分析。
相比于普通的信号博弈，Bayesian persuasion 中的信号发送者表现得既像 informed，又像 uninformed。其 informed 的地方在于，发送者所发送的信号是条件于 state 的；其 uninformed 的地方在于，发送者最大化事前的期望效用（无条件期望）。此外，信号结构并非是给定的，而全由发送者决定，即内生化了。
如前所示，由于信号发送者全权决定信号结构，他可以将信号设计得非常复杂，为简化分析，我们作出一个重要假设：发送者必须如实地告知接收者信号的实现结果。这基本上是在假设信号只有一层。
一般模型框架 信号发送者（简称「发送者」）所发送的具体内容是什么并不重要，重要的是，其发送的信号是一个（条件）分布，条件于 state，state 不同则分布不同，这种分布上的差异传递出了关于 state 的信息，迫使一个（贝叶斯式的）信号接收者（简称「接收者」）更新自己的信念，反而采取有利于发送者的行动。
模型设定 基本的模型设定如下：
State space $\Omega$ 是一个有限集； 接收者的 action space $A$ 是一个紧集； 发送者有定义在 $A\times\Omega$ 上的（关于 $a$）连续效用函数 $v(a,\omega)$； 接收者有定义在 $A\times\Omega$ 上的（关于 $a$）连续效用函数 $u(a,\omega)$； 发送者和接收者具有共同的关于 state 的先验信念 $\mu_0$，它是 $\Omega$ 上的概率测度，且严格为正（为了应用 Bayes 法则）； 一个信号 $\pi$ 是条件于 $\omega$ 的概率测度的集合：$\{\pi(\cdot|\omega)\}_{\omega\in\Omega}$，每个概率测度都定义在同一 realization space $S$ 上，$S$ 由发送者内生决定。 以概率论的视角来看，由于我们引入了条件概率 $\pi(s|\omega)$，$(\omega,s)$ 将有 $\Omega\times S$ 上的联合分布。</description></item></channel></rss>