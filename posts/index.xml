<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on 嘉树的世界</title><link>https://gaxu.xyz/posts/</link><description>Recent content in Posts on 嘉树的世界</description><generator>Hugo</generator><language>zh</language><copyright>2023–2024 嘉树.</copyright><lastBuildDate>Wed, 28 Aug 2024 20:00:49 +0800</lastBuildDate><atom:link href="https://gaxu.xyz/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>在 Mac 上管理多个 GitHub 账号</title><link>https://gaxu.xyz/posts/multiple-gh-accounts/</link><pubDate>Tue, 27 Aug 2024 19:29:37 +0800</pubDate><guid>https://gaxu.xyz/posts/multiple-gh-accounts/</guid><description>动机 我有两个 GitHub 账号，希望一个是面向工作，另一个则是私人的。那么，如何在一台 Mac 上无缝切换这个两个账号呢？本文列出了关键步骤。其他操作系统应当类似。
生成 SSH 密钥 GitHub 提供了两种方式与远程仓库建立联系：SSH 和 HTTPS。简单来说，当我们向远程仓库 push 代码时，HTTPS 每次都需要提供所谓的 access token（当然这个活其实也只是第一次 push 的时候需要，因为 Mac 会把这个 token 存放在钥匙串里面，以后就不需要手动输入了），而 SSH 使用一对公钥和私钥取得认证（事先生成，然后本地和远程分别拿着私钥和公钥），不需要记住用户名和 token。就我们的目的而言，只能用 SSH 来实现。
假设我们有两个账号，personal 和 work，以下我们分别为它们生成 SSH 密钥。更多账号操作也是一样的。
cd ~/.ssh ssh-keygen -t rsa -C &amp;#34;email@personal.com&amp;#34; -f &amp;#34;gh-personal&amp;#34; ssh-keygen -t rsa -C &amp;#34;email@work.com&amp;#34; -f &amp;#34;gh-work&amp;#34; 运行完了之后，在 .ssh 文件夹下我们得到了四个文件：
gh-personal gh-personal.pub gh-work gh-work.pub 其中带 .pub 扩展名的是存公钥的，不带的是存私钥的。
分配私钥和公钥 将私钥加入 SSH Agent 上一步只是生成了密钥，还需要把私钥加入 Mac 的钥匙串 (keychain)，也就是保存密码。
ssh-add --apple-use-keychain ~/.</description></item><item><title>半日杂记</title><link>https://gaxu.xyz/posts/half-day-diary/</link><pubDate>Sun, 25 Aug 2024 23:08:09 +0800</pubDate><guid>https://gaxu.xyz/posts/half-day-diary/</guid><description>师弟在我提出要去理发时向我强烈推荐了一家，我狐疑，追问之下原来是：他在此店被忽悠办了会员充了值，害怕店长哪天卷钱跑路了，希望尽快消费完。啊哈，那这个忙我当然要帮。
去了之后发现，这哪像会倒闭的样子！生意红火好嘛。当然也不排除有周日的加持。托尼老师很热情地向我推销卷烫染套餐，被我热情地回绝了。
剪完之后就在商场里闲逛，溜进一家「西西弗书店」，随意翻看能引起我兴趣的书，还真是颇有收获。试举几例：
原来鲁迅真的写过「在我的后园，可以看见墙外有两株树，一株是枣树，还有一株也是枣树」，这出自《野草》中《秋夜》的第一句，我一直以为这是一个梗来着。 曾国藩也有写日记的习惯，他是真写，真反思，真改变。 《冬牧场》这本书似乎去年大热，看了几页，哇塞，这个作者怎么可以写出这么可爱幽默俏皮温暖的文字！ 感悟就是，文字真的可以带来力量，内心的力量。愈加决定了！要多运动，多读书。
回去的时候顺便买了点水果，着实买贵了，以后还是去盒马买吧😥</description></item><item><title>专注力的流失</title><link>https://gaxu.xyz/posts/losing-concentration/</link><pubDate>Wed, 21 Aug 2024 12:43:47 +0800</pubDate><guid>https://gaxu.xyz/posts/losing-concentration/</guid><description>现在经常学着学着就很容易开小差，然后打开手机漫无目的地刷一刷，或者开始想些别的东西，这真的是一件很恐怖的事情。我的专注力在不断流失。
我幻想从清晨学到黄昏，心无旁骛地专注，因为时间在不知觉中的流动会给人一种高级的愉悦。我用了「幻想」，因为这种体验现在全无，但记忆中本科那会儿，是常能在图书馆坐上一天的。我的注意力为什么无法集中了呢？我在努力尝试思考的时候，大脑总会传出一个声音：这么复杂的问题，先歇会吧，反正时间有的是，也不差这一时半会儿。结果就是，我在每一个想要专注的节点都转移注意力去做了其他事，消磨的时间难以估量。我没法用劳逸结合来安慰自己，因为大部分时间我确实是处在「逸」的状态。这样做似乎很节省能量，但代价更严重──累积的畏难情绪和逐渐懒散的思维，学习节奏也全被打乱。
趁还有这样的意识的时候，是该刻意做点什么了吧。</description></item><item><title>集中不等式 (I)：Hoeffding 不等式</title><link>https://gaxu.xyz/posts/conctr-ineq-hoeffding/</link><pubDate>Sun, 11 Aug 2024 15:30:25 +0800</pubDate><guid>https://gaxu.xyz/posts/conctr-ineq-hoeffding/</guid><description>内容提要 介绍了集中不等式的概念，引入了 Chernoff 界方法，并以此证明了 Hoeffding 不等式。
什么是集中不等式？ Concentration inequalities，中文译作「集中不等式」，是概率论中的一类不等式，描述了一个随机变量的取值是否集中在某个特定的值附近，换句话说，相对于这个特定值偏离了多少，从概率上讲这个偏离的可能性又如何量化。这个特定的值通常取的是总体均值。数学上，这类不等式的形式可写作
$$ \mathbb{P}\{|X-\mu|&amp;gt;t\} \leq \text{something small} $$
这个不等式表明了，我们希望随机变量 $X$ 以很高的概率围绕在其均值附近波动。最简单、也最为我们熟悉的集中不等式当属 Chebyshev 不等式：如果 $X$ 的均值是 $\mu$，方差是 $\sigma^2$，那么
$$ \mathbb{P}\{|X-\mu|&amp;gt;t\} \leq \frac{\sigma^2}{t^2} $$
这个不等式当然是很一般的──我们只要求方差有限，除此之外并没有对 $X$ 的分布做更多要求。但是，在很多应用场景中，它还是太弱了，弱在不等式右边的东西不够小，或者更具体地说，当 $t\to\infty$ 时收敛到 0 的速度不够快。我们希望能有指数级别的收敛。
从渐进的观点看，当样本量足够大时，我们可以使用中心极限定理近似地得到样本均值偏离总体均值的概率，而正态分布的尾概率是指数衰减的。
Proposition 1.
若 $Z\sim\mathcal{N}(0,1)$，则对任意 $t&amp;gt;0$，都有
$$ \biggl(\frac1t-\frac{1}{t^3}\biggr)\cdot\frac{1}{\sqrt{2\pi}}e^{-t^2/2} \leq \mathbb{P}\{Z\geq t\} \leq \frac{1}{t}\cdot\frac{1}{\sqrt{2\pi}}e^{-t^2/2} $$
Proof. 对于上界，有
$$ \begin{align*} \mathbb{P}\{Z\geq t\} &amp;amp;= \frac{1}{\sqrt{2\pi}}\int_t^\infty e^{-x^2/2}\,dx \\ &amp;amp;\leq \frac{1}{\sqrt{2\pi}}\int_t^\infty \frac{x}{t}e^{-x^2/2}\,dx \\ &amp;amp;= \frac{1}{t\sqrt{2\pi}} \int_t^\infty -\frac{\partial}{\partial x}e^{-x^2/2}\,dx \\ &amp;amp;= \frac{1}{t}\cdot\frac{1}{\sqrt{2\pi}}e^{-t^2/2} \end{align*} $$</description></item><item><title>来个任意门吧</title><link>https://gaxu.xyz/posts/anywhere-door/</link><pubDate>Fri, 09 Aug 2024 10:31:47 +0800</pubDate><guid>https://gaxu.xyz/posts/anywhere-door/</guid><description>这几天实在太热了🥵🥵，每次往返学校都流一身汗，不想去学校了，但是呆家里就容易躺。两难呐😑
要是有个任意门就好了，可以舒心往返，两难自解🥹</description></item><item><title>拒绝完美主义</title><link>https://gaxu.xyz/posts/noperfect/</link><pubDate>Thu, 08 Aug 2024 22:20:20 +0800</pubDate><guid>https://gaxu.xyz/posts/noperfect/</guid><description>很多时候我都很难开始做一件事，总是觉得没准备好就不能开始，一来二去就浪费了很多时间。作为J人就这点不好，虽然每次都要搞个计划，但着实难以实施──总是在完善计划。其实我也知道，这是完美主义在作祟，拖延只是其导致的现象。
这种心理偏执是一种相当的阻碍。以前我一直以为，要开始做研究，那必然是先要尽可能把「所有」相关的基础知识都吃透，然后才能游刃有余。且不说是不是真的吃透了就一定能融会贯通，但就说吃透这些知识的时间成本就很巨大，那么要开始一个项目，得准备多少光阴？现在我意识到，在具备必要的基础知识之后，就可以边学边做了，这是「干中学」。这个方法不仅杜绝了前期漫长准备带来的时间上的不确定性，而且效率其实是很高的。另外也不要追求一次成功，第一次尝试能有一个还不错的结果能证明可行性就足够了。
说到底完美主义背后可能还是缺了自信，因为如果足够自信，就不会怀疑对过程的把控能力，同时对于结果也有一个理性的认知，那么就不会停留于准备阶段。大胆地开始，小心地推进，追求一个可接受的初步结果，然后逐步完善，这种态度才是不伤身心的。</description></item><item><title>Macro QE 备考 (II): 新古典增长和世代交叠模型</title><link>https://gaxu.xyz/posts/macro-qe-preparation-ngm-olg/</link><pubDate>Tue, 27 Jun 2023 15:08:53 +0800</pubDate><guid>https://gaxu.xyz/posts/macro-qe-preparation-ngm-olg/</guid><description>Info
本系列未能完成，只出了两期，因为复习进度太慢，最终换成手写笔记了。且作留恋。
Overlapping Generations 资本过度积累和动态无效率 我们对 OLG 模型的竞争均衡同一个社会计划者的中心化决策进行对比，考察竞争均衡是否是 Pareto 最优的。社会计划者意图最大化所有代际的加权平均效用：
$$ \sum_{t=0}^\infty \xi_t[u(c_{1,t})+\beta u(c_{2,t+1})] $$
其中 $\xi_t$ 是社会计划者赋予代际 $t$ 的权重。同时，还要服从总的资源约束：
$$ F(K_t,L_t) = K_{t+1} + L_tc_{1,t} + L_{t-1}c_{2,t} $$
两边同除以 $L_t$，得到
$$ f(k_t) = (1+n)k_{t+1} + c_{1,t} + \frac{c_{2,t}}{1+n} $$
对于同一个体青年期和老年期的消费分配，一阶条件为
$$ \frac{u&amp;rsquo;(c_{1,t})}{\beta u&amp;rsquo;(c_{2,t+1})} = \frac{1}{1+n}\frac{dc_{2,t+1}}{dk_{t+1}} = f&amp;rsquo;(k_{t+1}) $$
回忆在竞争均衡中，一阶条件是
$$ u&amp;rsquo;(c_{1,t}) = \beta R_{t+1} u&amp;rsquo;(c_{2,t+1}) $$
而 $R_{t+1} = f'(k_{t+1})$，因此社会计划者对一个个体青年期和老年期的消费配置同该个体自身的最大化决策是一致的，在这一点上市场配置是有效率的。
然而，由于社会计划者给每一代个体分配了不同的权重（$\xi_t$ 随 $t$ 变化），可以想见代际之间资源配置不会相同，这是区别于竞争均衡的。
考虑一个具体的权重设定：$\xi_t = \xi^t$。我们使用 Lagrange 函数：</description></item><item><title>Macro QE 备考 (I): 动态规划</title><link>https://gaxu.xyz/posts/macro-qe-preparation-dynamic-programming/</link><pubDate>Fri, 23 Jun 2023 22:35:19 +0800</pubDate><guid>https://gaxu.xyz/posts/macro-qe-preparation-dynamic-programming/</guid><description>Info
本系列未能完成，只出了两期，因为复习进度太慢，最终换成手写笔记了。且作留恋。
Sequential form and recursive form 我们只考虑平稳的动态规划问题，「平稳」是说即时收益函数 $u$ 和状态变量的演化约束 $G$ 不显式地依赖于时间 $t$。
有两种表述形式：序列式和递归式，递归式也就是 Bellman 方程。序列式如下：
$$ \begin{align*} V^*(x_0) = \max_{\{x_t\}_{t=0}^\infty} &amp;amp;\quad\sum_{t=0}^\infty\beta^tu(x_t,x_{t+1}), \\ \text{s.t.}&amp;amp;\quad x_{t+1}\in G(x_t), \\ &amp;amp;\quad x_0 \text{ is given.} \end{align*} $$
递归式如下：
$$ V(x) = \max_{y\in G(x)} u(x,y) + \beta V(y). $$
两种形式所确立的值函数是等价的。
欧拉方程 在以上递归式中，一阶条件为
$$ u_2(x,y) + \beta V&amp;rsquo;(y) = 0. $$
此外，由包络定理，有
$$ V&amp;rsquo;(x) = u_1(x,y). $$
假设最优 policy 的函数（因为是平稳的，故不显式依赖于 $t$）：$y = \pi(x)$，便有欧拉方程
$$ u_2(x,\pi(x)) + \beta u_1\bigl(\pi(x),\pi(\pi(x))\bigr) = 0.</description></item><item><title>Micro QE 备考练习</title><link>https://gaxu.xyz/posts/micro-qe-preparation/</link><pubDate>Fri, 09 Jun 2023 16:22:12 +0800</pubDate><guid>https://gaxu.xyz/posts/micro-qe-preparation/</guid><description>本来计划做一份所有往年题的答案（已经全部做好了但希望打出一份电子版），但不幸考前🐑了，只完成此三题的誊抄，姑且留个纪念吧。
Problem 1 (stochastic dominance) Consider lotteries $L_1\equiv(p_1\circ x_1,p_2\circ x_2)$ and $L_2\equiv(1\circ \bar{x})$, where $\bar{x} &amp;gt; p_1x_1+p_2x_2$, and $\bar{x}&amp;lt;x_2$. Let $x$ denote the outcome of $L_1$ and $\widetilde{x}$ the outcome of $L_2$. ($L_2$ is a trivial lottery. So $\widetilde{x}$ is a random variable that equals $\bar{x}$ with probability one.) Let $z$ denote the outcome of lottery
$$ L_3 \equiv (q_1\circ z_1, \dots, q_i\circ z_i, \dots, q_n\circ z_n), $$
where $n$ is some finite number greater than 1.</description></item><item><title>计量复习笔记 (VIII)：自回归估计与 (A)DF 检验</title><link>https://gaxu.xyz/posts/ecmt-notes-ar-adf/</link><pubDate>Sun, 30 Apr 2023 12:02:47 +0800</pubDate><guid>https://gaxu.xyz/posts/ecmt-notes-ar-adf/</guid><description>Info
本系列是2023年春季学期《应用计量经济学》期末复习笔记，仅涵盖时间序列部分，对应 Hansen (2022) Econometrics 第14和16章的内容。
内容提要 介绍了单位根假设下自回归系数的 OLS 估计量的渐进分布，以及由此而来的 (Augmented) Dicky-Fuller 单位根检验。
AR(1) 的估计和单位根检验 设 $Y_t$ 是一个 AR(1) 过程：$Y_t = \alpha Y_{t-1} + e_t$，为简化问题1，这里 $e_t$ 是平稳遍历的鞅差分，方差为 $\sigma_e^2$。
在平稳情形下，即 $|\alpha| &amp;lt; 1$ 时，我们对 OLS 估计量 $\hat{\alpha}$ 以 $\sqrt{n}$ 作为 scaling，容易得到
$$ \sqrt{n}(\hat{\alpha} - \alpha) = \sqrt{n}\frac{\sum_{t=2}^nY_{t-1}e_t}{\sum_{t=2}^nY_{t-1}^2} = \frac{n^{-1/2}\sum_{t=2}^nY_{t-1}e_t}{n^{-1}\sum_{t=2}^nY_{t-1}^2} \to_d N(0,1-\alpha^2) $$
可见，当 $\alpha \to 1$，上式将依概率收敛到 0。这也说明，$\sqrt{n}$ 放缩对于单位根是不够的。
事实上，当 $\alpha = 1$，即单位根情形下2，应采用 $n$ 作为 scaling：
$$ n(\hat{\alpha} - 1) = \frac{n^{-1}\sum_{t=2}^nY_{t-1}e_t}{n^{-2}\sum_{t=2}^nY_{t-1}^2} $$</description></item><item><title>计量复习笔记 (VII)：单位根序列的均值和趋势</title><link>https://gaxu.xyz/posts/ecmt-notes-fclt-means-trends/</link><pubDate>Sat, 29 Apr 2023 13:28:11 +0800</pubDate><guid>https://gaxu.xyz/posts/ecmt-notes-fclt-means-trends/</guid><description>Info
本系列是2023年春季学期《应用计量经济学》期末复习笔记，仅涵盖时间序列部分，对应 Hansen (2022) Econometrics 第14和16章的内容。
内容提要 介绍了随机游走序列的样本均值、带趋势项回归、除均值和除趋势等过程的渐进分布，它们都涉及布朗运动。
样本均值过程 设 $Y_t = \sum_{\tau=1}^te_\tau$ 是上一讲定义的部分和序列，阶跃函数 $Y_n(r)$ 的具体定义如下：
$$ Y_n(r) = \frac{1}{\sqrt{n}}Y_{\lfloor nr\rfloor} = \frac{1}{\sqrt{n}}Y_t \quad \text{for } \textstyle r\in\left[\frac{t}{n},\frac{t+1}{n}\right) \quad t = 1,\dots,n $$
也就是说，$Y_n(r)$ 在区间 $\left[\frac{t}{n},\frac{t+1}{n}\right)$ 上是常数（当然是对固定的 $\omega$），因此可写为
$$ \frac{1}{\sqrt{n}}Y_t = n\cdot\frac1n Y_n(r) = n\int_{t/n}^{(t+1)/n} Y_n(r)\,dr $$
于是，对样本均值 $\bar{Y}_n = n^{-1}\sum_{t=1}^nY_t$，我们有
$$ \begin{align*} \frac{1}{\sqrt{n}}\bar{Y}_n &amp;amp;= \sum_{t=1}^n\int_{t/n}^{(t+1)/n} Y_n(r)\,dr = \int_{1/n}^{1+1/n} Y_n(r)\,dr \\ &amp;amp;= \int_0^1Y_n(r)\,dr + \frac{1}{n^{3/2}}Y_n - \frac{1}{n^{3/2}}Y_0 \\ &amp;amp;= \int_0^1Y_n(r)\,dr + o_p(1) \end{align*} $$</description></item><item><title>计量复习笔记 (VI)：Beveridge-Nelson 分解</title><link>https://gaxu.xyz/posts/ecmt-notes-bndecomp/</link><pubDate>Fri, 28 Apr 2023 23:42:25 +0800</pubDate><guid>https://gaxu.xyz/posts/ecmt-notes-bndecomp/</guid><description>Info
本系列是2023年春季学期《应用计量经济学》期末复习笔记，仅涵盖时间序列部分，对应 Hansen (2022) Econometrics 第14和16章的内容。
内容提要 介绍了 Beveridge-Nelson 分解，并通过此法证明了更一般的平稳序列（允许序列相关）的部分和过程的极限分布。
Beveridge-Nelson 分解 在上一讲的例子中，$e_t$ 是一个平稳遍历的鞅差分，这是一个比较特殊的平稳序列，现在我们想知道对于更一般的平稳序列，其（标准化的）部分和过程 $S_n(r)$ 是否也能通过 FCLT 得到一个极限分布。
我们考虑 $e_t$ 是一个 $\text{MA}(\infty)$ 的情况，它仍然是平稳的，只是允许了序列相关。具体而言，设
$$ e_t = \Theta(L)u_t = \sum_{j=0}^\infty\theta_ju_{t-j} $$
其中 $u_t$ 是一个平稳遍历的鞅差分，方差为 $\sigma^2$。
Beveridge-Nelson 分解依赖于对多项式 $\Theta(z)$ 的分解：
$$ \begin{align*} \Theta(z) &amp;amp;= \Theta(1) + [\Theta(z)-\Theta(1)] \\ &amp;amp;= \textstyle\Theta(1) + \left(\sum_{j=0}^\infty\theta_jz^j-\sum_{j=0}^\infty\theta_j\right) \\ &amp;amp;= \textstyle\Theta(1) + (1-z)\sum_{j=0}^\infty\left(-\theta_j\sum_{k=0}^{j-1}z^k\right) \\ &amp;amp;= \textstyle\Theta(1) + (1-z)\sum_{k=0}^\infty\left(-\sum_{j=k+1}^\infty\theta_j\right)z^k \\ &amp;amp;= \textstyle\Theta(1) + (1-z)\sum_{k=0}^\infty\theta_k^* z^k \\ &amp;amp;= \Theta(1) + (1-z)\Theta^{*}(z) \end{align*} $$</description></item><item><title>计量复习笔记 (V)：泛函中心极限定理</title><link>https://gaxu.xyz/posts/ecmt-notes-fclt/</link><pubDate>Thu, 27 Apr 2023 20:46:10 +0800</pubDate><guid>https://gaxu.xyz/posts/ecmt-notes-fclt/</guid><description>Info
本系列是2023年春季学期《应用计量经济学》期末复习笔记，仅涵盖时间序列部分，对应 Hansen (2022) Econometrics 第14和16章的内容。
内容提要 介绍了泛函中心极限定理，并用其证明了鞅差分部分和过程的极限分布。
泛函中心极限定理 一个随机过程 $\{e_t(\omega)\}_{t=1}^n$，当我们固定 $\omega$ 时（即一次 realization），我们就得到了一条样本路径，关于时间的函数。我们可以像在绘制折线图那样，将离散点连接起来，就得到了一条 $[1,n]$ 上连续的曲线；当然，也可以像后文那样，在离散点之间用水平线插值，得到一个阶跃函数，只在有限个点处不连续，这不会影响核心性质。不失一般性，我们总可以将区间 $[1,n]$ 对应到 $[0,1]$ 上，也就是说，将一个 $[1,n]$ 上的函数水平伸缩到 $[0,1]$ 上，这不难做到。最后，我们将得到一个 $C[0,1]$ 中的函数，$C[0,1]$ 是全体 $[0,1]$ 上（几乎处处）连续的实值函数构成的函数空间1。
以上的操作事实上建立了从 $\mathbb{R}^{n}$ 中的点（因为 $e_1(\omega),\dots,e_n(\omega)$ 是 $n$ 个实数值）到 $C[0,1]$ 中的函数的映射，在这个映射下会有一个像测度，它描述了 $C[0,1]$ 上随机函数的分布，或者说连续时间随机过程的分布。泛函中心极限定理关心的问题就是，当 $n\to\infty$ 时，这个分布的收敛情况。
一个典型的 $C[0,1]$ 上的概率测度是 Wiener 测度，它是 Wiener 过程（又称 Brownian motion）的分布。
以下我们直接给出泛函中心极限定理 (Functional Central Limit Theorem, FCLT)：
Theorem 1.
对随机过程 $\{e_t(\omega)\}_{t=1}^\infty$，记 $S_t = \sum_{\tau=1}^te_{\tau}$ 为部分和序列，构造一个阶跃函数 $S_n(\cdot)\colon[0,1]\to\mathbb{R}$：
$$ S_n(r) = \frac{1}{\sqrt{n}} S_{\lfloor nr\rfloor} = \frac{1}{\sqrt{n}}\sum_{t=1}^{\lfloor nr\rfloor}e_t $$</description></item><item><title>计量复习笔记 (IV)：时间趋势与收敛速率</title><link>https://gaxu.xyz/posts/ecmt-notes-time-trends/</link><pubDate>Tue, 25 Apr 2023 19:14:11 +0800</pubDate><guid>https://gaxu.xyz/posts/ecmt-notes-time-trends/</guid><description>Info
本系列是2023年春季学期《应用计量经济学》期末复习笔记，仅涵盖时间序列部分，对应 Hansen (2022) Econometrics 第14和16章的内容。
内容提要 介绍了含时间趋势回归中 OLS 估计量的渐进分布，揭示了收敛速率的差异。
时间趋势回归 考虑线性回归模型
$$ Y_t = \beta_0 + \beta_1 t + e_t $$
其中 ${e_t}$ 是平稳遍历的鞅差分，方差为 $\sigma^2$。
假设我们有 $t=1,\dots,n$ 的样本，OLS 估计量（的偏误）就是
$$ \begin{pmatrix} \hat{\beta}_0-\beta_0 \\ \hat{\beta}_1-\beta_1 \end{pmatrix} = \begin{pmatrix} n &amp;amp; \sum_{t=1}^n t \\ \sum_{t=1}^n t &amp;amp; \sum_{t=1}^n t^2 \end{pmatrix}^{-1} \begin{pmatrix} \sum_{t=1}^n e_t \\ \sum_{t=1}^n te_t \end{pmatrix} $$
很显然，$\frac1n\bm{X}'\bm{X}$ 是不收敛的，因为 $\sum_{t=1}^n t = O(n^2)$，$\sum_{t=1}^n t^2 = O(n^3)$。不过，我们可以做一些 rescaling 凑出收敛。
首先将 $\bm{X}'\bm{X}$ 统一调成 $O(1)$，这意味着放缩因子是</description></item><item><title>计量复习笔记 (III)：几个话题</title><link>https://gaxu.xyz/posts/ecmt-notes-some-notions/</link><pubDate>Mon, 24 Apr 2023 12:18:41 +0800</pubDate><guid>https://gaxu.xyz/posts/ecmt-notes-some-notions/</guid><description>Info
本系列是2023年春季学期《应用计量经济学》期末复习笔记，仅涵盖时间序列部分，对应 Hansen (2022) Econometrics 第14和16章的内容。
内容提要 这一讲不是单个概念，而是好几个话题。因为单个的内容都比较少，所以我把它们都放在这里。当然，每一个话题都可以拓展为很丰富的内容，但由于课上也是选择性介绍的，这里我也就没有再去探索（留待以后），因为往后的重心是非平稳时间序列。
介绍了鞅差分中心极限定理、线性投影和 Wold 分解定理。
鞅差分中心极限定理 鞅 (martingale) 是一类非常重要的随机过程，鞅差分 (martingale difference sequence, m.d.s.) 顾名思义就是鞅的差分。这里我们不通过鞅来定义鞅差分，而是直接给出鞅差分的定义：
Definition 1.
随机过程 $\{e_t\}$ 若适应于滤流 (filtration) $\{\mathcal{F}_t\}$ 且满足
$$ \mathbb{E}(e_t|\mathcal{F_{t-1}}) = 0 \quad\text{almost surely} $$
则称之为鞅差分序列。
容易验证一个 m.d.s. 是零均值、序列不相关的。
不加证明地给出鞅差分中心极限定理：
Theorem 2.
若 $\{e_t\}$ 是平稳遍历的 m.d.s.，且 $\mathbb{E}(e_t^2) = \sigma^2 &amp;lt;\infty$，则有
$$ \sqrt{n}\bar{e}_n = \frac{1}{\sqrt{n}}\sum_{t=1}^ne_t \to_d N(0,\sigma^2) $$
此定理特别适合我们的需要，因为之前已经介绍了平稳和遍历，为了得到一个中心极限定理，只需额外要求序列是一个鞅差分。此定理的严格证明可参考 Davidson (1994) 定理 24.3，它事实上是 McLeish (1974) 鞅差分 CLT 的一个较弱的推论，平稳遍历将保证那个定理中的各项条件得到满足。
课本中还介绍了 混合 (mixing) 的概念，它是比遍历更强的要求，但思想是相同的，就是渐进独立性（见上一讲定理 4 下面的讨论）。这里不作更多介绍。</description></item><item><title>计量复习笔记 (II)：遍历性</title><link>https://gaxu.xyz/posts/ecmt-notes-ergodicity/</link><pubDate>Sat, 22 Apr 2023 20:22:42 +0800</pubDate><guid>https://gaxu.xyz/posts/ecmt-notes-ergodicity/</guid><description>Info
本系列是2023年春季学期《应用计量经济学》期末复习笔记，仅涵盖时间序列部分，对应 Hansen (2022) Econometrics 第14和16章的内容。
内容提要 引入一个重要概念：遍历性 (ergodicity)，并证明了（弱版本的）遍历定理，该定理是时间序列版本的大数定律。
遍历性 上一讲介绍了平稳性，它本质上诱导出一个保测变换。但平稳性仍不足以建立起大数定律，例如，考虑一个平凡的时间序列 $Y_t = Y$，它没有任何时间维度上的变动，很显然，它是平稳的，然而 $\frac1n\sum Y_t = Y$ 并不收敛到 $\mathbb{E}(Y)$。大数定律还需要时间序列是遍历的。顺带一提，遍历性理论已经发展成了一个数学分支，在时间序列中的应用只是其诸多应用之一。
在定义遍历性之前我们先介绍一些必要概念。称事件 $A$ 在变换 $T$ 下是 不变的(invariant) 若 $A$ 在 $T$ 下的原像也是 $A$，即 $T^{-1}A = A$。例如，在时间序列中，我们接触到最多的变换之一就是时间位移变换 $(\delta x)_t = x_{t+1}$，很显然，$\mathbb{R}^{\mathbb{Z}}$ 在 $\delta$ 下就是不变的。称事件 $A$ 是 平凡的(trivial) 如果 $\mathbb{P}(A)$ 等于 0 或 1。称一个变换 $T$ 是 遍历的 若所有在 $T$ 下不变的事件 $A\in\mathcal{F}$（$\mathcal{F}$ 是 $\sigma$ 域）都是平凡的，换言之，没有非平凡不变事件。
现在给出时间序列遍历性的正式定义：
Definition 1.
设时间序列 $\{Y_t\}_{t\in\mathbb{Z}}$ 的分布为 $\mu$，相应地有概率空间 $(\mathbb{R}^{\mathbb{Z}},\mathcal{B}(\mathbb{R}^{\mathbb{Z}}),\mu)$。若位移变换 $\delta: \mathbb{R}^{\mathbb{Z}}\to\mathbb{R}^{\mathbb{Z}}$ 是遍历的，则称 $\{Y_t\}$ 是遍历的。 可以看到，数学上，平稳性要求位移变换是一个保测变换（见上一讲对定理 2 的证明，在那里还说明了像测度 $\mu$ 是如何定义的），而遍历性要求位移变换是遍历的。那么，该如何理解遍历性呢？直观来讲，它意味着一个时间序列随着时间的演进将最终到达样本空间内的所有状态，而被吸收到特定状态的概率为零。可以想见，当一个时间序列既是平稳又是遍历的，那么一条样本路径随机而均匀地（此处「均匀」指按照单个 $Y_t$ 分布的均匀）访问了整个样本空间，于是它们的样本均值就能很好地刻画总体均值，这就是遍历定理的基本思想。</description></item><item><title>计量复习笔记 (I)：严格平稳性</title><link>https://gaxu.xyz/posts/ecmt-notes-stationarity/</link><pubDate>Sat, 22 Apr 2023 00:58:32 +0800</pubDate><guid>https://gaxu.xyz/posts/ecmt-notes-stationarity/</guid><description>Info
本系列是2023年春季学期《应用计量经济学》期末复习笔记，仅涵盖时间序列部分，对应 Hansen (2022) Econometrics 第14和16章的内容。
内容提要 介绍了时间序列中的一个重要概念：严格平稳性（如无特别说明，平稳性均指代严格平稳），并证明了对平稳序列的任意（可测）变换所得序列仍是平稳的（原书定理 14.2）。
平稳时间序列 对于构建时间序列的严格且正式的理论而言，我们需要的是严格平稳性，弱平稳（宽平稳、协方差平稳）是不足够的。平稳性对于一列随机变量序列，即随机过程，施加了特别的结构，从而使我们在离开独立性世界后依然能发展出类似大数定律、中心极限定理的重要理论。
首先给出严格平稳时间序列的定义：
Definition 1.
随机过程 $\{Y_t\}_{t\in\mathbb{Z}}$ 若满足：给定任意的 $r\in\mathbb{Z}$，$(Y_t,\dots,Y_{t+r})$ 的联合分布与 $t$ 无关，则称之为平稳过程。 以随机过程的术语来说，平稳时间序列的分布具有 位移不变 (shift-invariant) 的性质。如果我们采用测度论的严格表述，就是：对于 $\mathbb{R}$ 的任意 Borel 子集 $B_0,B_2,\dots,B_r$，以及任意的 $t$ 和 $\tau$，都有
$$ \mathbb{P}\{\omega\colon Y_t(\omega)\in B_0,\dots,Y_{t+r}(\omega)\in B_r\} = \mathbb{P}\{\omega\colon Y_\tau(\omega)\in B_0,\dots,Y_{\tau+r}(\omega)\in B_r\} $$
这就是在表述 $(Y_t,\dots,Y_{t+r})$ 和 $(Y_{\tau},\dots,Y_{\tau+r})$ 具有相同分布。
值得一提，有时我们会看到略有不同的定义：
若对任意的 $t_1,t_2,\dots,t_r$，$(Y_{t_1},\dots,Y_{t_r})$ 的联合分布与 $(Y_{t_1+k},\dots,Y_{t_r+k})$ 相同，而与 $k$ 无关，则称 ${Y_t}$ 是平稳序列。
乍一看，这个定义似乎更一般，但它和上面的定义是等价的。要从前述定义推出此定义，只需注意到联合分布相同，则边缘分布必定相同，而 $(Y_{t_1},\dots,Y_{t_r})$ 的分布实际上就是 $(Y_t)_{t=t_1}^{t_r}$ 的边缘分布（不失一般性，假设 $t_1,\dots,t_r$ 由小到大排列）。
平稳时间序列的变换 现在给出一个很强大的定理，它表明了平稳时间序列在任意可测变换下仍可保留平稳性。
Theorem 2.</description></item><item><title>矩阵的秩、核范数与矩阵补全</title><link>https://gaxu.xyz/posts/nuclear-norm-min/</link><pubDate>Sat, 08 Apr 2023 16:06:52 +0800</pubDate><guid>https://gaxu.xyz/posts/nuclear-norm-min/</guid><description>大约三周以前，听了一个presentation，讲到了 network 研究中度量关系网络的矩阵的 「低秩」(low rank) 性质。之后我在浏览一些高维计量文章时，又见到了这个概念，以及 「核范数」(nuclear norm, aka trace norm)。我印象里应该见过它们很多次，有些模糊的记忆片段，突然想起和硕士期间导师的交流中他提到过，遂从聊天记录中找到一些珍贵文件，当时他让我学习一下关于 「矩阵补全」(matrix recovery, or matrix completion) 的内容，我没来得及看。那么这几天就学习学习，说不定以后能派上用场。
内容提要 本文将从矩阵恢复问题出发，介绍秩的最小化问题如何转变为一个核范数的最小化问题，前者是一个非凸的优化问题，很难求解，后者是一个凸优化问题，尽管不可求微分，但凸问题总是更易于求解的。
Motivation 我们所感兴趣的问题是，如何基于非常有限的信息复原一个（低秩）矩阵。这一话题原本来自于工程实践的需要，例如计算机视觉领域的图像降噪，我们知道图像是由像素点构成的，因而整个图像可以视为一个大矩阵，当有一些像素被破坏，得到的就是一个不完整的矩阵，对图像降噪就是要补全那些污损或缺失的像素点；又如著名的 Netflix 问题（类似地，在国内语境下是豆瓣问题）：Netflix 用户评分矩阵只包含了某些用户对某些电影的评分，而不是每个用户对所有电影的评分（如下图所示），我们希望能推测出那些缺失的评分。这些问题都涉及到矩阵补全。
Rating Matrix (Source: Yuejie Chi, 2018, Lecture Notes) 那么，这和低秩又有什么关系呢？很显然，在没有任何限制条件下去补全那些未知的项，我们有无数种填充方式。想要唯一地重建一个矩阵，这个矩阵必须有些特殊的结构作为限制，而低秩就是一个合理的结构。低秩意味着，矩阵的列向量高度线性相关──它们扩展形成的线性空间是低维的。说得更加人话就是，数据中的大部分波动都由少数几个因子驱动。
现在可能又要问了，低秩在实践中是一个合理的假设吗？以 Netflix 评分矩阵为例，直觉上，同一类用户群体的行为、特征有很高的相似性，因此他们的潜在评分高度一致，这样评分矩阵的「主成分」实际上就是几个群体的评价，从而是低秩的。
核范数最小化 低秩矩阵的补全可分为两类方法 (Gu et al. 2014)：矩阵分解法 和 求解秩最小化问题法。前者用两个低秩矩阵之积作为构造方式，可留待以后学习；后者是本文要讨论的内容。
秩最小化问题的正式表述 假设真实矩阵是 $\bm{M}$，我们所观测到的元素集合是 $\{M_{i,j}\colon (i,j)\in\Omega\}$。秩最小化问题就表述为
$$ \min_{\bm{X}}\ \text{rank}(\bm{X}) \quad \text{s.t. } X_{i,j} = M_{i,j},\ \text{for every }(i,j)\in\Omega $$
为方便起见，定义算子 $\mathcal{P}_{\Omega}$ 如下：
$$ [\mathcal{P}_{\Omega}(\bm{X})]_{i,j} = \begin{cases} X_{i,j} &amp;amp; \text{if }(i,j)\in\Omega \\ 0 &amp;amp; \text{otherwise} \end{cases} $$</description></item><item><title>Ridge Regression</title><link>https://gaxu.xyz/posts/ridge-regression/</link><pubDate>Fri, 17 Mar 2023 13:37:45 +0800</pubDate><guid>https://gaxu.xyz/posts/ridge-regression/</guid><description>内容提要 一周以前（3月7日）考计量期中，第一题是证明岭回归估计量的渐进分布的，我没有完整地写出来，这里面还是有些技巧，之前我并不熟悉，现在总结在这里。
岭回归简介 Ridge regression，中文译名「岭回归」，是一种利用 正则化方法 处理 不适定问题 的技术。我们知道，使用 OLS 时是要求自变量之间不存在完全多重共线性的，即回归元矩阵必须是列满秩的，否则最小二乘问题没有唯一解；但如果某些变量间的相关性很高，甚至接近完全相关，OLS 估计量的方差将会相当大，估计精度大大下降。这个问题在待估参数很多时常常发生。岭回归通过对系数向量的 $L^2$ 范数（的平方）施加一个惩罚，控制系数的整体大小，达到以一定程度的偏误换取更低方差的目的（见 bias-variance tradeoff）。
Formulation 考虑线性模型：$y_i = \bm{x}_i^\prime\bm{\beta} + \varepsilon_i$，$i=1,\dots,N$。其中 $\bm{x}_i$ 和 $\bm{\beta}$ 都是 $p$ 维向量。我们更喜欢表示为矩阵形式：
$$ \bm{Y} = \bm{X}\bm{\beta} + \bm{\mathcal{E}} $$
其中 $\bm{Y} = (y_1,\dots,y_N)^\prime$，$\bm{X} = (\bm{x}_1,\dots,\bm{x}_N)^\prime$，$\bm{\mathcal{E}} = (\varepsilon_1,\dots,\varepsilon_N)^\prime$。假设 $\mathbb{E}(\varepsilon_i|\bm{x}_i) = 0$ 以及 $\mathbb{E}(\varepsilon_i^2|\bm{x}_i) = \sigma^2$，并假设 $\{(\bm{x}_i,y_i)\}_{i=1}^n$ 是独立同分布的。
岭回归估计量 $\hat{\bm{\beta}}$ 来自如下带有惩罚项的最小二乘问题：
$$ \min_{\bm{\beta}}\quad \frac1n(\bm{Y}-\bm{X}\bm{\beta})^\prime(\bm{Y}-\bm{X}\bm{\beta}) + \lambda\bm{\beta}^\prime\bm{\beta} \tag{$*$} $$
这里 $\lambda$ 是一个参数，它衡量了惩罚的大小。当 $\lambda=0$ 时，该问题就是 OLS；当 $\lambda\to\infty$ 时，$\bm{\beta} = \bm{0}$。事实上，这个问题等价于一个有约束的最小二乘：</description></item><item><title>Bayesian Persuasion</title><link>https://gaxu.xyz/posts/bayesian-persuasion/</link><pubDate>Wed, 08 Mar 2023 22:25:46 +0800</pubDate><guid>https://gaxu.xyz/posts/bayesian-persuasion/</guid><description>内容提要 本文是基于 Kamenica and Gentzkow (2011) 的学习笔记，仅对微观课上覆盖的内容做了分析，目的只是通过考试，并不是对文章的全面剖析，但由于上课时一头雾水，为了彻底理解均衡的概念，有必要深入学习。以下分为两节，第一节直接介绍模型框架和重要推论，第二节给出解题的一般方法，此方法是几何直观的，依赖于第一节的分析。
相比于普通的信号博弈，Bayesian persuasion 中的信号发送者表现得既像 informed，又像 uninformed。其 informed 的地方在于，发送者所发送的信号是条件于 state 的；其 uninformed 的地方在于，发送者最大化事前的期望效用（无条件期望）。此外，信号结构并非是给定的，而全由发送者决定，即内生化了。
如前所示，由于信号发送者全权决定信号结构，他可以将信号设计得非常复杂，为简化分析，我们作出一个重要假设：发送者必须如实地告知接收者信号的实现结果。这基本上是在假设信号只有一层。
一般模型框架 信号发送者（简称「发送者」）所发送的具体内容是什么并不重要，重要的是，其发送的信号是一个（条件）分布，条件于 state，state 不同则分布不同，这种分布上的差异传递出了关于 state 的信息，迫使一个（贝叶斯式的）信号接收者（简称「接收者」）更新自己的信念，反而采取有利于发送者的行动。
模型设定 基本的模型设定如下：
State space $\Omega$ 是一个有限集； 接收者的 action space $A$ 是一个紧集； 发送者有定义在 $A\times\Omega$ 上的（关于 $a$）连续效用函数 $v(a,\omega)$； 接收者有定义在 $A\times\Omega$ 上的（关于 $a$）连续效用函数 $u(a,\omega)$； 发送者和接收者具有共同的关于 state 的先验信念 $\mu_0$，它是 $\Omega$ 上的概率测度，且严格为正（为了应用 Bayes 法则）； 一个信号 $\pi$ 是条件于 $\omega$ 的概率测度的集合：$\{\pi(\cdot|\omega)\}_{\omega\in\Omega}$，每个概率测度都定义在同一 realization space $S$ 上，$S$ 由发送者内生决定。 以概率论的视角来看，由于我们引入了条件概率 $\pi(s|\omega)$，$(\omega,s)$ 将有 $\Omega\times S$ 上的联合分布。</description></item></channel></rss>