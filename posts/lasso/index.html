<!doctype html><html lang=en-US><head><title>LASSO 的收敛</title>
<meta charset=utf-8><meta name=X-UA-Compatible content="IE=edge"><meta name=google-site-verification content><meta content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0" name=viewport><meta content="telephone=no" name=format-detection><meta name=description content><meta name=renderer content="webkit"><meta name=theme-color content="#ffffff"><meta property="og:url" content="https://gaxu.xyz/posts/lasso/"><meta property="og:site_name" content="嘉树的世界"><meta property="og:title" content="LASSO 的收敛"><meta property="og:description" content="线性模型 通篇考虑线性模型 $$ \bm{Y} = \bm{X}\bm{\beta}^* + \bm{\varepsilon} $$ 其中 $\bm{\varepsilon}\in\text{subG}_n(\sigma^2)$，这表示对任意 $\bm{v}\in\mathbb{R}^n$ 且 $\|\bm{v}\|_2\leq1$，$\bm{v}'\bm{\varepsilon}\in\text{subG}(\sigma^2)$。此外，假设 $\bm{X}$ 是固定的。
损失函数的收敛 LASSO 估计量就是 $$ \hat{\bm{\beta}} := \arg\min_{\bm{\beta}\in\mathbb{R}^p} \frac{1}{2n}\|\bm{Y}-\bm{X}\bm{\beta}\|_2^2 + \lambda_n\|\bm{\beta}\|_1 $$ $\ell_1$ 范数作为惩罚项使得解具有稀疏性 (sparsity)。
记事件 $A := \{\lambda_n \geq \frac1n\|\bm{X}'\bm{\varepsilon}\|_{\infty}\}$。
Theorem 1."><meta property="og:locale" content="zh"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-09-04T13:33:52+08:00"><meta property="article:modified_time" content="2024-09-05T13:41:35+08:00"><meta property="article:tag" content="机器学习"><meta property="article:tag" content="高维理论"><meta property="article:tag" content="LASSO"><meta name=twitter:card content="summary"><meta name=twitter:title content="LASSO 的收敛"><meta name=twitter:description content="线性模型 通篇考虑线性模型 $$ \bm{Y} = \bm{X}\bm{\beta}^* + \bm{\varepsilon} $$ 其中 $\bm{\varepsilon}\in\text{subG}_n(\sigma^2)$，这表示对任意 $\bm{v}\in\mathbb{R}^n$ 且 $\|\bm{v}\|_2\leq1$，$\bm{v}'\bm{\varepsilon}\in\text{subG}(\sigma^2)$。此外，假设 $\bm{X}$ 是固定的。
损失函数的收敛 LASSO 估计量就是 $$ \hat{\bm{\beta}} := \arg\min_{\bm{\beta}\in\mathbb{R}^p} \frac{1}{2n}\|\bm{Y}-\bm{X}\bm{\beta}\|_2^2 + \lambda_n\|\bm{\beta}\|_1 $$ $\ell_1$ 范数作为惩罚项使得解具有稀疏性 (sparsity)。
记事件 $A := \{\lambda_n \geq \frac1n\|\bm{X}'\bm{\varepsilon}\|_{\infty}\}$。
Theorem 1."><script async src="https://www.googletagmanager.com/gtag/js?id=G-LER46KQN8K"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-LER46KQN8K")}</script><script src=/js/toc.js></script><link type=text/css rel=stylesheet href=/vendor/css/bootstrap.min.css><link rel=stylesheet href=/scss/journal.min.ad2da485e6e2508f0b90c8b9bbc39f6fe2a3c27aec57f6da5f61d27ca10988d0.css integrity="sha256-rS2khebiUI8LkMi5u8Ofb+KjwnrsV/baX2HSfKEJiNA=" media=screen><link rel=stylesheet href=/scss/dark-mode.min.f7229ad242ba49e1ea468f47af5b72c60a1e55bb98a14d37522a08158bfbd591.css integrity="sha256-9yKa0kK6SeHqRo9Hr1tyxgoeVbuYoU03UioIFYv71ZE=" media=screen><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Lora:500,500italic,700,700italic|Roboto:400,400italic,700,700italic|Montserrat:500,500italic,700,700italic|Fira+Mono:500,700|Noto+Serif+TC:500,700|Noto+Serif+SC:500,700|Material+Icons&display=swap"><script src=https://unpkg.com/@waline/client@v2/dist/waline.js></script><link rel=stylesheet href=https://unpkg.com/@waline/client@v2/dist/waline.css><script>console.log("Hello from 'layouts/partials/extended_head.html'")</script><link rel=stylesheet href=/vendor/css/lxgwwenkaiscreenr.css><script defer src=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.3.0/js/all.min.js></script><link rel=stylesheet href=/scss/custom/_custom.min.1897837e079bbc071513d784df607fc241ee7ec7ff434808792ff70d41b2c157.css integrity="sha256-GJeDfgebvAcVE9eE32B/wkHufsf/Q0gIeS/3DUGywVc=" media=screen><link rel=stylesheet href=/vendor/css/heti.min.css><script src=/vendor/js/heti.min.js></script><script defer>function domReady(){var e=document.querySelector(".post-subtitle");e&&e.classList.add("heti"),e=document.querySelector("#post-content"),e&&e.classList.add("heti"),document.querySelectorAll(".post-item-summary").forEach(e=>{e.classList.add("heti")})}document.addEventListener("DOMContentLoaded",function(){document.removeEventListener("DOMContentLoaded",arguments.callee,!1),domReady()});const heti=new Heti(".heti");heti.autoSpacing(),window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],macros:{bm:["\\boldsymbol{#1}",1]},processEscapes:!0,processEnvironments:!0},svg:{scale:.962,fontCache:"global"},options:{skipHtmlTags:["script","noscript","style","textarea","pre"],enableMenu:!1}},function(){var e=document.createElement("script");e.src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js",e.async=!0,document.addEventListener("DOMContentLoaded",function(){document.head.appendChild(e)})}()</script><script>document.addEventListener("DOMContentLoaded",function(){var e,t=document.getElementsByClassName("collapsible");for(e=0;e<t.length;e++)t[e].addEventListener("click",function(){this.classList.toggle("active");var e=this.nextElementSibling;e.style.display==="block"?e.style.display="none":e.style.display="block"})})</script></head><body><div id=app><div class=single-column-drawer-container id=drawer v-bind:class="{ 'single-column-drawer-container-active': isDrawerOpen }"><div class=drawer-content><div class=drawer-menu><a class="a-block drawer-menu-item false" href=/about>关于我
</a><a class="a-block drawer-menu-item active" href=/posts>归档
</a><a class="a-block drawer-menu-item false" href=/categories>分类
</a><a class="a-block drawer-menu-item false" href=/tags>标签
</a><a class="a-block drawer-menu-item false" href=/index.xml>订阅</a><div class=toc><div class=toc-content><center>目录</center><ul><ul><li><a href=#%e7%ba%bf%e6%80%a7%e6%a8%a1%e5%9e%8b class=nav-线性模型>线性模型</a></li><li><a href=#%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0%e7%9a%84%e6%94%b6%e6%95%9b class=nav-损失函数的收敛>损失函数的收敛</a></li><li><a href=#lambda_n-%e7%9a%84%e9%80%89%e5%8f%96%e5%92%8c-lasso-%e7%9a%84%e6%85%a2%e7%8e%87 class=nav-lambda_n-的选取和-lasso-的慢率>$\lambda_n$ 的选取和 LASSO 的慢率</a></li><li><a href=#lasso-%e7%9a%84%e5%bf%ab%e7%8e%87 class=nav-lasso-的快率>LASSO 的快率</a></li><li><a href=#%e5%8f%82%e8%80%83 class=nav-参考>参考</a></li></ul></div></div></div></div></div><transition name=fade><div id=drawer-mask v-bind:class="{ 'single-column-drawer-mask': mounted }" v-if=isDrawerOpen v-on:click=toggleDrawer></div></transition><nav id=navBar class="navbar sticky-top navbar-light single-column-nav-container"><div id=navBackground class=nav-background></div><div class="container container-narrow nav-content"><button id=nav_dropdown_btn class=nav-dropdown-toggle type=button v-on:click=toggleDrawer>
<i class=material-icons>menu
</i></button>
<a id=navTitle class=navbar-brand href=https://gaxu.xyz/>嘉树的世界
</a><button type=button class=nav-darkmode-toggle id=darkModeToggleButton2>
<i class=material-icons id=darkModeToggleIcon2>dark_mode</i></button></div></nav><div class=single-column-header-container id=pageHead v-bind:style="{ transform: 'translateZ(0px) translateY('+.3*scrollY+'px)', opacity: 1-navOpacity }"><a href=https://gaxu.xyz/><div class=single-column-header-title>嘉树的世界</div><div class=single-column-header-subtitle>靡不有初，鲜克有终</div></a></div><div id=content><div id=streamContainer class=stream-container><div class="post-list-container post-list-container-shadow"><div class=post><div class=post-head-wrapper-text-only><div class=post-title>LASSO 的收敛<div class=post-meta>嘉树 &nbsp;
<time itemprop=datePublished>2024-09-04 13:33
</time>&emsp;
<i class=material-icons>folder</i>
<a href=/categories/econometrics>Econometrics</a>
&nbsp;
<i class=material-icons>label</i>
<a href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0>机器学习</a>,
<a href=/tags/%E9%AB%98%E7%BB%B4%E7%90%86%E8%AE%BA>高维理论</a>,
<a href=/tags/lasso>LASSO</a></div></div></div><div class=post-body-wrapper><div class=post-body v-pre><div id=post-content><h2 id=线性模型>线性模型&nbsp;<a class=hash-link href=#线性模型><i class="fas fa-link"></i></a></h2><p>通篇考虑线性模型</p>$$
\bm{Y} = \bm{X}\bm{\beta}^* + \bm{\varepsilon}
$$<p>其中 $\bm{\varepsilon}\in\text{subG}_n(\sigma^2)$，这表示对任意 $\bm{v}\in\mathbb{R}^n$ 且 $\|\bm{v}\|_2\leq1$，$\bm{v}'\bm{\varepsilon}\in\text{subG}(\sigma^2)$。此外，假设 $\bm{X}$ 是固定的。</p><h2 id=损失函数的收敛>损失函数的收敛&nbsp;<a class=hash-link href=#损失函数的收敛><i class="fas fa-link"></i></a></h2><p>LASSO 估计量就是</p>$$
\hat{\bm{\beta}} := \arg\min_{\bm{\beta}\in\mathbb{R}^p} \frac{1}{2n}\|\bm{Y}-\bm{X}\bm{\beta}\|_2^2 + \lambda_n\|\bm{\beta}\|_1
$$<p>$\ell_1$ 范数作为惩罚项使得解具有稀疏性 (sparsity)。</p><p>记事件 $A := \{\lambda_n \geq \frac1n\|\bm{X}'\bm{\varepsilon}\|_{\infty}\}$。</p><div class=thm><p id=thm:consistency class="thm-title thm-theorem">Theorem 1.</p><div class="thm-inner thm-theorem"><p>若事件 $A$ 成立，则</p>$$
\frac{1}{n}\|\bm{X}(\hat{\bm{\beta}}-\bm{\beta}^*)\|_2^2 \leq 4\|\bm{\beta}^*\|_1\lambda_n
$$</div></div><div class=thm><button type=button class=collapsible><div id=thm-proof-1 class=thm-title-proof>Proof.</div></button><div class=proof-content><div class=thm-inner-proof><p>首先，我们证明如下基本不等式：</p>$$
\frac{1}{2n}\|\bm{X}(\hat{\bm{\beta}}-\bm{\beta}^*)\|_2^2 \leq \frac{1}{n}\bm{\varepsilon}'\bm{X}(\hat{\bm{\beta}}-\bm{\beta}^*) + \lambda_n(\|\bm{\beta}^*\|_1-\|\hat{\bm{\beta}}\|_1)
$$<p>此不等式事实上直接来自于</p>$$
\frac{1}{2n}\|\bm{Y}-\bm{X}\hat{\bm{\beta}}\|_2^2 + \lambda_n\|\hat{\bm{\beta}}\|_1 \leq \frac{1}{2n}\|\bm{Y}-\bm{X}\bm{\beta}^*\|_2^2 + \lambda_n\|\bm{\beta}^*\|_1
$$<p>只需将 $\bm{Y} = \bm{X}\bm{\beta}^* + \bm{\varepsilon}$ 代入即可得到。</p><p>以下给出 $\frac{1}{2n}\|\bm{X}(\hat{\bm{\beta}}-\bm{\beta}^*)\|_2^2$ 的界：</p>$$
\begin{align*}
\frac{1}{2n}\|\bm{X}(\hat{\bm{\beta}}-\bm{\beta}^*)\|_2^2 &\leq \frac{1}{n}\bm{\varepsilon}'\bm{X}(\hat{\bm{\beta}}-\bm{\beta}^*) + \lambda_n(\|\bm{\beta}^*\|_1-\|\hat{\bm{\beta}}\|_1) \\
&\leq \frac{1}{n}\|\bm{X}'\bm{\varepsilon}\|_\infty\|\hat{\bm{\beta}}-\bm{\beta}^*\|_1 + \lambda_n(\|\bm{\beta}^*\|_1-\|\hat{\bm{\beta}}\|_1) \\
&\leq \frac{1}{n}\|\bm{X}'\bm{\varepsilon}\|_\infty\|(\|\hat{\bm{\beta}}\|_1+\|\bm{\beta}\|_1) + \lambda_n(\|\bm{\beta}^*\|_1-\|\hat{\bm{\beta}}\|_1) \\
&= \|\hat{\bm{\beta}}\|_1\biggl(\frac{1}{n}\|\bm{X}'\bm{\varepsilon}\|_\infty-\lambda_n\biggr) + \|\bm{\beta}^*\|_1\biggl(\frac{1}{n}\|\bm{X}'\bm{\varepsilon}\|_\infty+\lambda_n\biggr) \\
&\leq 2\lambda_n\|\bm{\beta}^*\|_1
\end{align*}
$$<p>第二行使用了 Hölder 不等式，第三行使用了三角不等式，最后一行是因为事件 $A$ 成立。</p></div><div class=thm-end-proof><i class="fas fa-square"></i> <a href=#thm-proof-1><i class="fas fa-arrow-circle-up"></i></a></div></div></div><p>关于此定理有几点需要注意：</p><ol><li>不等式所给出的界取决于调谐参数 $\lambda_n$，而它又取决于样本量 $n$。</li><li>此不等式在事件 $A$ 上成立，因此如果事件 $A$ 有很大概率发生，则此不等式也有很大概率发生（不低于事件 $A$ 发生的概率）。</li></ol><h2 id=lambda_n-的选取和-lasso-的慢率>$\lambda_n$ 的选取和 LASSO 的慢率&nbsp;<a class=hash-link href=#lambda_n-的选取和-lasso-的慢率><i class="fas fa-link"></i></a></h2><p>我们当然希望 $\lambda_n$ 越小越好，但是我们又要保证事件 $A$ 发生的概率。为此，我们施加一个额外的假设。</p><div class=thm><p id=assump:max class="thm-title thm-assumption">Assumption 2.</p><div class="thm-inner thm-assumption">设 $\max_j\|\bm{X}_j\|\leq\sqrt{Cn}$ 对某个 $C>0$ 成立，这里 $\bm{X}_j$ 是 $\bm{X}$ 的第 $j$ 列。</div></div><p>在这个假设下，对任意 $t>0$ 我们有</p>$$
\begin{align*}
\mathbb{P}\biggl\{\frac{1}{n}\|\bm{X}'\bm{\varepsilon}\|_\infty\geq t\biggr\} &= \mathbb{P}\biggl\{\frac{1}{n}\max_j|\bm{X}_j'\bm{\varepsilon}|\geq t\biggr\} \\
&\leq \sum_j \mathbb{P}\biggl\{\frac{1}{n}|\bm{X}_j'\bm{\varepsilon}|\geq t\biggr\} \\
&\leq \sum_j \mathbb{P}\biggl\{\frac{|\bm{X}_j'\bm{\varepsilon}|}{n\|\bm{X}_j\|_2}\geq\frac{t}{\|\bm{X}_j\|_2}\biggr\} \\
&\leq 2p\exp\biggl(-\frac{t^2n}{2\sigma^2C}\biggr)
\end{align*}
$$<p>最后一行利用了 sub-Gaussian 的性质：如果 $X\in\text{subG}(\sigma^2)$，则对任意 $t>0$ 有</p>$$
\mathbb{P}\{X\geq t\} \leq \exp\biggl(-\frac{t^2}{2\sigma^2}\biggr)
$$<p>给定一个 $\delta>0$，我们选择</p>$$
t = \sqrt{\frac{2\sigma^2C}{n}[\log(1/\sigma)+\log(2p)]}
$$<p>那么以上概率就会</p>$$
\mathbb{P}\biggl\{\frac{1}{n}\|\bm{X}'\bm{\varepsilon}\|_\infty\geq t\biggr\} \leq 2p\exp\biggl(-\frac{t^2n}{2\sigma^2C}\biggr) \leq \delta
$$<p>也就是说，我们取 $\lambda_n$ 为上述 $t$ 值，那么事件 $A$ 发生的概率就至少是 $1-\delta$。我们有以下推论。</p><div class=thm><p id=coro:slowrate class="thm-title thm-corollary">Corollary 3 (Slow rate for the LASSO).</p><div class="thm-inner thm-corollary"><p>至少以概率 $1-\delta$，我们有</p>$$
\frac{1}{n}\|\bm{X}(\hat{\bm{\beta}}-\bm{\beta}^*)\|_2^2 \leq 4\|\bm{\beta}^*\|_1\sigma\sqrt{\frac{2C}{n}[\log(1/\sigma)+\log(2p)]}
$$</div></div><p>为什么叫 slow rate？在最优子集选择 (best subset selection) 中，我们可以推出 (reference?)</p>$$
\frac{1}{n}\|\bm{X}(\hat{\bm{\beta}}-\bm{\beta}^*)\|_2^2 \lesssim \|\bm{\beta}\|_0\sigma^2\frac{\log n+\log p}{n}
$$<p>而在上述推论中，如果我们选择 $\delta=1/n$，则会得到</p>$$
\frac{1}{n}\|\bm{X}(\hat{\bm{\beta}}-\bm{\beta}^*)\|_2^2 \lesssim \|\bm{\beta}^*\|_1\sigma\sqrt{\frac{\log n+\log p}{n}}
$$<p>这多了一个根号，因此比最优子集选择的收敛率要慢。</p><h2 id=lasso-的快率>LASSO 的快率&nbsp;<a class=hash-link href=#lasso-的快率><i class="fas fa-link"></i></a></h2><p>我们是否能改进前述收敛速率呢？注意到如果 $\mu_{\min}(\bm{X}'\bm{X})\geq\gamma_n>0$，则有</p>$$
\|\hat{\bm{\beta}}-\bm{\beta}^*\|_2 \leq \frac{1}{\gamma_n}\|\bm{X}(\hat{\bm{\beta}}-\bm{\beta}^*)\|_2^2
$$<p>而当 $p>n$ 时，$\mu_{\min}(\bm{X}'\bm{X})=0$，此时我们无法得到 $\|\hat{\bm{\beta}}-\bm{\beta}^*\|_2$ 的收敛。我们需要对 $\bm{X}$ 施加额外的假设，有很多种方式，但基本思想就一个：让 $\gamma_n$ 和零保持距离。</p><p>以下介绍一种广泛使用的假设：受限特征值条件 (restricted eigenvalue condition, RE)。</p><div class=thm><p id=def:re class="thm-title thm-definition">Definition 4 (Restricted Eigenvalue).</p><div class="thm-inner thm-definition"><p>给定 $\alpha\geq1$ 和 $S\subseteq\{1,\dots,p\}$ 且 $S\neq\emptyset$，令</p>$$
\mathcal{C}_\alpha(S) = \{\bm{\Delta}\in\mathbb{R}^p\colon\|\bm{\Delta}_{S^\complement}\|_1\leq\alpha\|\bm{\Delta}_S\|_1\}
$$<p>其中 $S^\complement = \{1,\dots,p\}\backslash S$，$\bm{\Delta}_{S}=(\Delta_j)_{j\in S}$。</p><p>如果存在某个 $\alpha\geq1$ 和 $\kappa>0$，对任意的 $\bm{\Delta}\in\mathcal{C}_\alpha(S)$ 都有</p>$$
\frac{1}{n}\|\bm{X}\bm{\Delta}\|_2^2 \geq \kappa\|\bm{\Delta}\|_2^2
$$<p>则称 $n\times p$ 的矩阵 $\bm{X}$ 满足 $\text{RE}(\alpha,\kappa)$ 条件。</p></div></div><p>下面我们花一些篇幅来从直觉上理解这一条件。</p><p>取 $\bm{\Delta}=\hat{\bm{\beta}}-\bm{\beta}^*$。前面我们已经证明了 $\frac1n\|\bm{X}\bm{\Delta}\|_2^2$ 能够以大概率取很小的值，但这不意味着 $\|\bm{\Delta}\|_2^2$ 也可以很小，因为函数 $\bm{\Delta}\mapsto\frac1n\|\bm{X}\bm{\Delta}\|_2^2$ 在 $\hat{\bm{\beta}}-\bm{\beta}^*$ 附近可能很平坦，也就是说，在较宽的一个范围内我们都能得到较小的损失函数值。</p><p>如果 $\mu_{\min}(\bm{X}'\bm{X})/n$ 和零保持一定距离，譬如</p>$$
\kappa\|\bm{\Delta}\|_2^2 \leq \frac{1}{n}\|\bm{X}\bm{\Delta}\|_2^2
$$<p>这将意味着 $\bm{\Delta}\mapsto\frac1n\|\bm{X}\bm{\Delta}\|_2^2$ 有足够的曲率（不是平坦的曲线）。我们只需要这个条件对某些 $\bm{\Delta}$ 成立，即 RE 所表述的那样。这些 $\bm{\Delta}$ 被集合 $\mathcal{C}_\alpha(S)$ 所刻画，它是这样一个集合：指标集 $S$ 所对应的那些系数要充分大于非 $S$ 对应的系数。这直觉上规定了 $S$ 和 $S^\complement$ 对应的系数值能被区分开的一类系数向量。</p><p>令 $S = \{\beta_j^*\colon\beta_j^*\neq0\}$ 是非零系数的集合，$s=|S|$ 是非零系数的个数，或者称之为<em>稀疏性</em>。在 RE 条件下，有如下定理。</p><div class=thm><p id=thm:fast class="thm-title thm-theorem">Theorem 5 (Fast rate of the LASSO).</p><div class="thm-inner thm-theorem"><p>设存在某个 $\kappa>0$ 使得 $\bm{X}$ 满足 $\text{RE}(3,\kappa)$ 条件。若</p>$$
\lambda_n \geq \frac{2}{n}\|\bm{X}'\bm{\varepsilon}\|_\infty
$$<p>则 LASSO 估计量 $\hat{\beta}$ 满足</p>$$
\begin{align*}
\frac{1}{n}\|\bm{X}(\hat{\bm{\beta}}-\bm{\beta}^*)\|_2^2 &\leq \frac{9s\lambda_n^2}{\kappa} \\
\|\hat{\bm{\beta}}-\bm{\beta}^*\|_2 &\leq \frac{3\sqrt{s}\lambda_n}{\kappa}
\end{align*}
$$</div></div><div class=thm><button type=button class=collapsible><div id=thm-proof-2 class=thm-title-proof>Proof.</div></button><div class=proof-content><div class=thm-inner-proof><p>首先证明，当 $\lambda_n$ 满足上述定理的条件时，有 $\hat{\bm{\Delta}}=\hat{\bm{\beta}}-\bm{\beta}^*\in\mathcal{C}_3(S)$。</p><p>因 $\hat{\bm{\beta}}$ 是最小化问题的解，有</p>$$
\frac{1}{2n}\|\bm{Y}-\bm{X}\hat{\bm{\beta}}\|_2^2 + \lambda_n\|\hat{\bm{\beta}}\|_1 \leq \frac{1}{2n}\|\bm{Y}-\bm{X}\bm{\beta}^*\|_2^2 + \lambda_n\|\bm{\beta}^*\|_1
$$<p>代入 $\bm{Y} = \bm{X}\bm{\beta}^* + \bm{\varepsilon}$，整理得到</p>$$
0 \leq \frac{1}{2n}\|\bm{X}\hat{\bm{\Delta}}\|_2^2 \leq \frac1n\bm{\varepsilon}'\bm{X}\hat{\bm{\Delta}} + \lambda_n(\|\bm{\beta}^*\|_1-\|\hat{\bm{\beta}}\|_1)
$$<p>根据 $S$ 的定义，$\|\bm{\beta}^*\|_1 = \|\bm{\beta}_S^*\|_1$。另外，可将 $\|\hat{\bm{\beta}}\|_1$ 写为</p>$$
\|\hat{\bm{\beta}}\|_1 = \|\hat{\bm{\beta}}_S\|_1 + \|\hat{\bm{\beta}}_{S^\complement}\|_1 = \|\bm{\beta}_S^*+\hat{\bm{\Delta}}_S\|_1 + \|\hat{\bm{\Delta}}_{S^\complement}\|_1
$$<p>带入到前面的不等式得到</p>$$
\begin{align*}
0 \leq \frac{1}{2n}\|\bm{X}\hat{\bm{\Delta}}\|_2^2 &\leq \frac1n\bm{\varepsilon}'\bm{X}\hat{\bm{\Delta}} + \lambda_n(\|\bm{\beta}_S^*\|_1-\|\bm{\beta}_S^*+\hat{\bm{\Delta}}_S\|_1 - \|\hat{\bm{\beta}}_{S^\complement}\|_1) \\
&\leq \frac{1}{n}\|\bm{X}'\bm{\varepsilon}\|_\infty\|\hat{\bm{\Delta}}\|_1 + \lambda_n(\|\bm{\beta}_S^*\|_1-\|\bm{\beta}_S^*+\hat{\bm{\Delta}}_S\|_1 - \|\hat{\bm{\Delta}}_{S^\complement}\|_1) \\
&\leq \frac{1}{n}\|\bm{X}'\bm{\varepsilon}\|_\infty\|\hat{\bm{\Delta}}\|_1 + \lambda_n(\|\hat{\bm{\Delta}}_S\|_1 - \|\hat{\bm{\Delta}}_{S^\complement}\|_1) \\
&\leq \frac12\lambda_n\|\hat{\bm{\Delta}}\|_1 + \lambda_n(\|\hat{\bm{\Delta}}_S\|_1 - \|\hat{\bm{\Delta}}_{S^\complement}\|_1) \\
&= \frac12\lambda_n\|\hat{\bm{\Delta}}_S\|_1 + \frac12\lambda_n\|\hat{\bm{\Delta}}_{S^\complement}\|_1 + \lambda_n(\|\hat{\bm{\Delta}}_S\|_1 - \|\hat{\bm{\Delta}}_{S^\complement}\|_1) \\
&= \frac{3}{2}\lambda_n\|\hat{\bm{\Delta}}_S\|_1 - \frac12\lambda_n\|\hat{\bm{\Delta}}_{S^\complement}\|_1
\end{align*}
$$<p>第二行使用了 Hölder 不等式，第三行使用了三角不等式，第四行使用了条件 $\lambda_n \geq \frac{2}{n}\|\bm{X}'\bm{\varepsilon}\|_\infty$。这就导致了 $\|\hat{\bm{\Delta}}_{S^\complement}\|_1 \leq 3\|\hat{\bm{\Delta}}_S\|_1$，也就证明了 $\hat{\bm{\Delta}}\in\mathcal{C}_3(S)$。</p><p>第二步，我们将使用 RE 条件。注意到</p>$$
\lambda_n(3\|\hat{\bm{\Delta}}_S\|_1-\|\hat{\bm{\Delta}}_{S^\complement}\|_1) \leq 3\lambda_n\|\hat{\bm{\Delta}}_S\|_1 \leq 3\lambda_n\sqrt{s}\|\hat{\bm{\Delta}}_S\|_2 \leq 3\lambda_n\sqrt{s}\|\hat{\bm{\Delta}}\|_2
$$<p>这里使用了 $\ell_1$ 和 $\ell_2$ 范数之间的关系：对 $\bm{x}\in\mathbb{R}^d$，有 $\|\bm{x}\|_2\leq\|\bm{x}\|_1\leq\sqrt{d}\|\bm{x}\|_2$，这可通过数形结合来理解。从而</p>$$
\begin{align*}
\frac{1}{n}\|\bm{X}\hat{\bm{\Delta}}\|_2^2 &\leq \lambda_n(3\|\hat{\bm{\Delta}}_S\|_1-\|\hat{\bm{\Delta}}_{S^\complement}\|_1) \\
&\leq 3\lambda_n\sqrt{s}\|\hat{\bm{\Delta}}\|_2 \\
&\leq 3\lambda_n\sqrt{s}\frac{\|\bm{X}\hat{\bm{\Delta}}\|_2}{\sqrt{n\kappa}}
\end{align*}
$$<p>最后一行用了 RE 条件。整理后就得到</p>$$
\frac{1}{n}\|\bm{X}\hat{\bm{\Delta}}\|_2^2 \leq \frac{9s\lambda_n^2}{\kappa}
$$<p>使用此结论和 RE 就有第二个收敛</p>$$
\begin{align*}
\|\hat{\bm{\Delta}}\|_2 \leq \frac{\|\bm{X}\hat{\bm{\Delta}}\|_2}{\sqrt{n\kappa}} \leq \sqrt{\frac{9s\lambda_n^2}{\kappa^2}} = \frac{3\sqrt{s}\lambda_n}{\kappa}
\end{align*}
$$</div><div class=thm-end-proof><i class="fas fa-square"></i> <a href=#thm-proof-2><i class="fas fa-arrow-circle-up"></i></a></div></div></div><p>很显然，相比于 <a href=/posts/lasso/#thm:consistency>定理 1</a>，我们把不等式右边的界的收敛速度提升了（$\lambda_n$ 提升到 $\lambda_n^2$），此外还得到了 $\|\hat{\bm{\beta}}-\bm{\beta}^*\|$ 的收敛，所以称之为 LASSO 的快率。</p><p>我们也可以像 <a href=/posts/lasso/#coro:slowrate>推论 3</a> 那样用概率的形式表述，这里略去。</p><p>（未完待续～）</p><h2 id=参考>参考&nbsp;<a class=hash-link href=#参考><i class="fas fa-link"></i></a></h2><p>Alessandro Rinaldo&rsquo;s Lecture Notes (2018): <a href=https://www.stat.cmu.edu/~arinaldo/Teaching/36710/F18/Scribed_Lectures/Oct17.pdf>Oct 17</a>, <a href=https://www.stat.cmu.edu/~arinaldo/Teaching/36710/F18/Scribed_Lectures/Oct22.pdf>Oct 22</a>.</p><p>Rigollet, Philippe, and Jan-Christian Hütter (2023). &ldquo;High-Dimensional Statistics.&rdquo; <em>arXiv preprint</em>. <a href=https://arxiv.org/pdf/2310.19244.pdf>arXiv:2310.19244</a>.</p></div><div><hr width=100% id=EOF style="border-top:.6px solid #777;margin-top:2.5rem"><p style=color:#777>最后修改于 2024-09-05</p></div></div></div><nav class=post-pagination><a class=older-posts href=/posts/multiple-gh-accounts/>上回<br><em>在 Mac 上管理多个 GitHub 账号</em>
</a><a class=newer-posts>下回<br>已经到头啦。</a></nav><div class=post-comment-wrapper><div id=waline></div><script>Waline.init({el:"#waline",dark:"body.night",serverURL:"https://mysitecomments-2yzw3y3tk-cwleo.vercel.app"})</script></div></div></div></div></div><div id=sideContainer class=side-container><a class="a-block nav-head false" href=https://gaxu.xyz/><div class=nav-title>嘉树的世界</div><div class=nav-subtitle>靡不有初，鲜克有终</div></a><div class=nav-link-list><a class="a-block nav-link-item false" href=/about>关于我
</a><a class="a-block nav-link-item active" href=/posts>归档
</a><a class="a-block nav-link-item false" href=/categories>分类
</a><a class="a-block nav-link-item false" href=/tags>标签
</a><a class="a-block nav-link-item false" href=/index.xml>订阅</a></div><div class=nav-footer>由 <a href=https://gohugo.io>Hugo</a> 强力驱动<br>主题改动自 <a href=https://github.com/amazingrise/hugo-theme-diary>Diary</a><br>&copy;
2023–2024 嘉树.
本站遵循 <a href=https://creativecommons.org/licenses/by-nc/4.0/>CC-BY-NC 4.0</a> 协议</div></div><div id=extraContainer class=extra-container><div class=toc-wrapper><div class=toc><div class=toc-content><center>目录</center><ul><ul><li><a href=#%e7%ba%bf%e6%80%a7%e6%a8%a1%e5%9e%8b class=nav-线性模型>线性模型</a></li><li><a href=#%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0%e7%9a%84%e6%94%b6%e6%95%9b class=nav-损失函数的收敛>损失函数的收敛</a></li><li><a href=#lambda_n-%e7%9a%84%e9%80%89%e5%8f%96%e5%92%8c-lasso-%e7%9a%84%e6%85%a2%e7%8e%87 class=nav-lambda_n-的选取和-lasso-的慢率>$\lambda_n$ 的选取和 LASSO 的慢率</a></li><li><a href=#lasso-%e7%9a%84%e5%bf%ab%e7%8e%87 class=nav-lasso-的快率>LASSO 的快率</a></li><li><a href=#%e5%8f%82%e8%80%83 class=nav-参考>参考</a></li></ul></div></div></div><div class=pagination><a id=globalBackToTop class="pagination-action animated-visibility" href=#top :class="{ invisible: scrollY == 0 }"><i class="material-icons pagination-action-icon">keyboard_arrow_up
</i></a><a type=button class=pagination-action id=darkModeToggleButton><span class="material-icons pagination-action-icon" id=darkModeToggleIcon>dark_mode</span></a></div></div><div id=single-column-footer>由 <a href=https://gohugo.io>Hugo</a> 强力驱动<br>主题改动自 <a href=https://github.com/amazingrise/hugo-theme-diary>Diary</a><br>&copy;
2023–2024 嘉树.
本站遵循 <a href=https://creativecommons.org/licenses/by-nc/4.0/>CC-BY-NC 4.0</a> 协议</div></div><script src=/js/journal.js></script></body></html>